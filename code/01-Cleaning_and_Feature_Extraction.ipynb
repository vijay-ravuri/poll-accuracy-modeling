{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_extraction import person_finder, org_finder, state_agg, imputed_600, method_flagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls = pd.read_csv('../data/raw-polls.csv')\n",
    "pollster_ratings = pd.read_csv('../data/pollster-ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging our data let's take a look at if we have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['partisan', 'cand3_pct', 'bias', 'comment'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polls.loc[:, polls.isna().sum() > 0].columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partisan, cand3_pct, and comment having NAs is reasonable but bias should not have any. It is possible that 538 has a reason for excluding these bias calculations but there is none listed and the data dictionary notes the exact calculation for bias so we will fix this now to make our plots are more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.27550055675687e-07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polls['calc_bias'] = polls['margin_poll'] - polls['margin_actual'] # same formula as data dictionary\n",
    "np.mean(polls['error'] - np.abs(polls['calc_bias'])) # about as accurate as we can get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mean-Reverted Bias', 'Bias', 'House Effect',\n",
       "       'Average Distance from Polling Average (ADPA)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollster_ratings.loc[:, pollster_ratings.isna().sum() > 0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean-Reverted Bias                               44\n",
       "Bias                                             44\n",
       "House Effect                                     62\n",
       "Average Distance from Polling Average (ADPA)    108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollster_ratings[pollster_ratings.loc[:, pollster_ratings.isna().sum() > 0].columns].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data here is incomplete, for the bias variables those are due to not enough polls to analyze bias on 538's part. House Effect requires a comparison to other partisan polls in the same race so these are likely NA's for a valid reason. ADPA however is a bit troubling so let's analyze that more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    108.000000\n",
       "mean       2.277778\n",
       "std        2.629215\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        1.500000\n",
       "75%        2.000000\n",
       "max       18.000000\n",
       "Name: Polls Analyzed, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollster_ratings[pollster_ratings['Average Distance from Polling Average (ADPA)'].isna()]['Polls Analyzed'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "538 states their process for calculating ADPA is: we start by calculating how much the pollster’s average poll differs from the average of previous polls of that race — specifically, polls whose median field date was at least three days earlier and it is weighted based on the square root of the number of other polls in the field for each race.([source](https://fivethirtyeight.com/methodology/how-our-pollster-ratings-work/)) These NA values should be caused by races where there weren't enough other polls in the field, likely 0 previous polls. We will proceed as is because we do not intend to use any of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging our dataframes for ease of use\n",
    "df = pd.merge(left = polls, right = pollster_ratings, \n",
    "              how = 'left', \n",
    "              left_on = 'pollster_rating_id', right_on = 'Pollster Rating ID'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['partisan', 'cand3_pct', 'bias', 'comment', 'Rank', 'Pollster',\n",
       "       'Pollster Rating ID', 'Polls Analyzed', 'AAPOR/Roper', 'Banned by 538',\n",
       "       'Predictive Plus-Minus', '538 Grade', 'Mean-Reverted Bias',\n",
       "       'Races Called Correctly', 'Misses Outside MOE', 'Simple Average Error',\n",
       "       'Simple Expected Error', 'Simple Plus-Minus', 'Advanced Plus-Minus',\n",
       "       'Mean-Reverted Advanced Plus-Minus', '# of Polls for Bias Analysis',\n",
       "       'Bias', 'House Effect', 'Average Distance from Polling Average (ADPA)',\n",
       "       'Herding Penalty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, df.isna().sum() > 0].columns # Our merge caused new missing values so let's ensure there's no issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University of Maryland 1\n",
      "Brigham Young University 4\n",
      "Research America Inc. 3\n",
      "Insights West 9\n",
      "Sacred Heart University 2\n",
      "Hofstra University 2\n"
     ]
    }
   ],
   "source": [
    "# First we gather the missing IDs\n",
    "missing = [] \n",
    "for id in polls['pollster_rating_id'].unique():\n",
    "    if int(id) not in list(df['Pollster Rating ID']):\n",
    "        missing.append(id)\n",
    "\n",
    "# Then we gather the names of the pollsters\n",
    "missing_grades = []\n",
    "for id in missing:\n",
    "    for row in polls[polls['pollster_rating_id'] == id].values:\n",
    "        if row[8] not in missing_grades:\n",
    "            missing_grades.append(row[8])\n",
    "\n",
    "# Then we count how many polls total are effected\n",
    "for pollster in missing_grades:\n",
    "    print(pollster, polls[polls['pollster'] == pollster].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, a number of our polls were done by pollsters that are not in our pollster ratings. This is unexpected and unfortunate but we don't have any way to work around this issue. Once we reach the modelling stage we will be removing these polls because we don't have information on them and we have no reasonable way to impute their values. It is somewhat troubling that 538 doesn't have these rated but we don't have any means to fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's extract some features from the comment and methodology columns. Additionally, we will be cleaning the state column slightly to account for Maine and Nevada separate designations due to their unique presidential voting situation ([source](https://www.smithsonianmag.com/smart-news/why-do-maine-and-nebraska-split-their-electoral-votes-180976219/)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are defined in feature_extraction.py but basic descriptions are provided below\n",
    "\n",
    "# Marks whether an organization is mentioned in the comment\n",
    "# ie. 'for New York Daily News'\n",
    "df['org'] = df['comment'].apply(\n",
    "    lambda x: org_finder(x) if x is not np.nan else 0\n",
    "    )\n",
    "\n",
    "# Marks whether a person was mentioned in the comment\n",
    "# ie. 'for Charles E. Schumer'\n",
    "df['person'] = df['comment'].apply(\n",
    "    lambda x: person_finder(x) if x is not np.nan else 0\n",
    "    )\n",
    "\n",
    "# Marks whether unspecified is in the comment\n",
    "# ie. for unspecified Democratic sponsor\n",
    "df['anon'] = df['comment'].str.contains('unspecified').apply(\n",
    "    lambda x: 1 if x == True else 0\n",
    "    )\n",
    "\n",
    "# Marks whether poll is of 'voters' or 'registered voters'\n",
    "# ie. among 'voters' || among registered voters\n",
    "df['registered_voters'] = df['comment'].str.contains(\n",
    "    r\"registered voters|'voters'\"\n",
    "    ).apply(\n",
    "        lambda x: 1 if x == True else 0\n",
    "        ) # we are counting 'voters' as registered voters and not likely voters\n",
    "\n",
    "# Marks whether the comment notes the poll is an average of multiple polls/models\n",
    "# ie. average of multiple versions or turnout models listed in poll\n",
    "df['averaged'] = df['comment'].str.contains('average').apply(\n",
    "    lambda x: 1 if x == True else 0\n",
    "    )\n",
    "\n",
    "# Maps polls without partisan designations as No Party Listed (NPL)\n",
    "# We also have a single 'IND' poll which is short for independent.\n",
    "# This could refer to either an independent candidate or the Independent\n",
    "# Party (a fringe far-right party). See below for references on this race\n",
    "# but it seems like IND refers to an independent candidate in this case.\n",
    "df['partisan'] = df['partisan'].map(\n",
    "    {\n",
    "        'D' : 'D',\n",
    "        'R' : 'R',\n",
    "        np.nan : 'NPL',\n",
    "        'IND' : 'NPL' \n",
    "    }\n",
    ")\n",
    "\n",
    "# Gathers state designation from the location column which normally includes \n",
    "# district where applicable. The denotation 'agg' refers to us aggregating the\n",
    "# Maine and Nevada districts that vote separately into the state as a whole for\n",
    "# ease of analysis. \n",
    "# (https://www.smithsonianmag.com/smart-news/why-do-maine-and-nebraska-split-their-electoral-votes-180976219/)\n",
    "df['state_agg'] = df['location'].apply(state_agg)\n",
    "\n",
    "# Denotes polls with unspecified sample sizes that were imputed to be 600\n",
    "# per 538's standard practice. A number of these polls had sample sizes\n",
    "# that were not 600 and it is unclear why that is, this column only flags\n",
    "# polls where the comment says the sample size was imputed and the listed \n",
    "# sample size is 600. Our suspicion is that polls with this comment and \n",
    "# non-600 sample sizes were polls that were originally imputed and later\n",
    "# the correct value was added in but the comment was never changed.\n",
    "df['imputed_600'] = imputed_600(df)\n",
    "\n",
    "# Calculates the difference between median field date of the poll and \n",
    "# the election date. The values range from 1 day to 21 days as 538 only\n",
    "# includes the 3 weeks before the election in this dataset.\n",
    "df['days_bt_polldate_election'] = (pd.to_datetime(df['electiondate']) - pd.to_datetime(df['polldate'])).dt.days\n",
    "\n",
    "# Creates flag variables from the methodology column.\n",
    "# A poll can have multiple methodologies.\n",
    "# ie. IVR/Online --> IVR:1, Online:1, Live Phone:0 (not exhaustive just demonstrative of the concept)\n",
    "df = pd.merge(df, \n",
    "              pd.DataFrame(method_flagger(df['methodology'])), \n",
    "              left_index=True, \n",
    "              right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poll_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>race_id</th>\n",
       "      <th>year</th>\n",
       "      <th>race</th>\n",
       "      <th>location</th>\n",
       "      <th>type_simple</th>\n",
       "      <th>type_detail</th>\n",
       "      <th>pollster</th>\n",
       "      <th>pollster_rating_id</th>\n",
       "      <th>...</th>\n",
       "      <th>electiondate</th>\n",
       "      <th>cand1_actual</th>\n",
       "      <th>cand2_actual</th>\n",
       "      <th>margin_actual</th>\n",
       "      <th>error</th>\n",
       "      <th>bias</th>\n",
       "      <th>rightcall</th>\n",
       "      <th>advancedplusminus</th>\n",
       "      <th>comment</th>\n",
       "      <th>calc_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>53001</td>\n",
       "      <td>83867</td>\n",
       "      <td>1292</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010_Gov-G_ME</td>\n",
       "      <td>ME</td>\n",
       "      <td>Gov-G</td>\n",
       "      <td>Gov-G</td>\n",
       "      <td>Frederick Polls</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>11/2/2010</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.103192</td>\n",
       "      <td>for Eliot R. Cutler</td>\n",
       "      <td>-5.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      poll_id  question_id  race_id  year           race location type_simple  \\\n",
       "5093    53001        83867     1292  2010  2010_Gov-G_ME       ME       Gov-G   \n",
       "\n",
       "     type_detail         pollster  pollster_rating_id  ... electiondate  \\\n",
       "5093       Gov-G  Frederick Polls                 108  ...    11/2/2010   \n",
       "\n",
       "     cand1_actual cand2_actual  margin_actual error  bias rightcall  \\\n",
       "5093         43.0         31.8           11.2   5.2   NaN       1.0   \n",
       "\n",
       "      advancedplusminus              comment  calc_bias  \n",
       "5093           1.103192  for Eliot R. Cutler       -5.2  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polls[polls['partisan'] == 'IND'] # https://en.wikipedia.org/wiki/2010_Maine_gubernatorial_election\n",
    "                                  # https://en.wikipedia.org/wiki/Eliot_Cutler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputting Cleaned Dataframe with extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw-polls-updated.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
