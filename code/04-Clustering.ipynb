{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, HDBSCAN\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw-polls-updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the unrated pollsters we identified earlier\n",
    "unrated_pollsters = ['University of Maryland', 'Brigham Young University', 'Research America Inc.', \n",
    "                     'Insights West', 'Sacred Heart University', 'Hofstra University']\n",
    "\n",
    "unrated_indices = []\n",
    "\n",
    "for pollster in unrated_pollsters:\n",
    "    unrated_indices += list(df[df['pollster'] == pollster].index)\n",
    "\n",
    "df = df.drop(\n",
    "    index = unrated_indices\n",
    "    ).reset_index()# Resetting index fixes issues from dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're only going to select columns with measures on the poll level and\n",
    "# not pollster level metrics. For this approach we will rate our clusters\n",
    "# by how well they approximate pollster level differences.\n",
    "features = [\n",
    "    'year',\n",
    "    'type_simple',\n",
    "    'partisan',\n",
    "    'samplesize',\n",
    "    'margin_poll',\n",
    "    'advancedplusminus',\n",
    "    'imputed_600',\n",
    "    'anon',\n",
    "    'registered_voters',\n",
    "    'averaged',\n",
    "    'Text',\n",
    "    'Live Phone',\n",
    "    'Mail',\n",
    "    'Face-to-Face',\n",
    "    'IVR',\n",
    "    'Online',\n",
    "    'rightcall',\n",
    "    'error',\n",
    "    'calc_bias',\n",
    "    'days_bt_polldate_election'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "\n",
    "\n",
    "# We're going to define these stages now because all subsequent pipelines will want\n",
    "# to have access to them. Scaling is notably ommitted here because we will be comparing\n",
    "# Standard and MinMax scaling with each clustering algorithm.\n",
    "partisaner = Pipeline( # OneHotEncodes race type and partisan\n",
    "    [\n",
    "        ('ohe', OneHotEncoder(drop = 'first'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing_pipe = Pipeline(\n",
    "    [\n",
    "        ('ct', ColumnTransformer(\n",
    "            [\n",
    "                ('patrisan_ct', partisaner, ['partisan', 'type_simple'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8-Means Silhouette Score: 0.4115341273020342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1973</td>\n",
       "      <td>0.972884</td>\n",
       "      <td>5.638094</td>\n",
       "      <td>0.776736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960</td>\n",
       "      <td>-1.317735</td>\n",
       "      <td>5.545255</td>\n",
       "      <td>0.811735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>886</td>\n",
       "      <td>2.759526</td>\n",
       "      <td>4.545056</td>\n",
       "      <td>0.804740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1247</td>\n",
       "      <td>0.417674</td>\n",
       "      <td>6.191564</td>\n",
       "      <td>0.831997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1442</td>\n",
       "      <td>0.481553</td>\n",
       "      <td>3.768974</td>\n",
       "      <td>0.785021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1082</td>\n",
       "      <td>-3.509769</td>\n",
       "      <td>8.371774</td>\n",
       "      <td>0.799908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>867</td>\n",
       "      <td>-0.790300</td>\n",
       "      <td>4.982780</td>\n",
       "      <td>0.782007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1298</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>5.161009</td>\n",
       "      <td>0.829738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "0            1973  0.972884  5.638094  0.776736\n",
       "1            1960 -1.317735  5.545255  0.811735\n",
       "2             886  2.759526  4.545056  0.804740\n",
       "3            1247  0.417674  6.191564  0.831997\n",
       "4            1442  0.481553  3.768974  0.785021\n",
       "5            1082 -3.509769  8.371774  0.799908\n",
       "6             867 -0.790300  4.982780  0.782007\n",
       "7            1298  0.051148  5.161009  0.829738"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_pipe = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('kmeans', KMeans(n_init = 30, random_state = 42)) # Default is 8 clusters\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "clustered = pd.concat(\n",
    "    [X, pd.Series(kmeans_pipe['kmeans'].labels_, name = 'cluster')]\n",
    "    , axis = 1)\n",
    "\n",
    "print(\n",
    "    \"8-Means Silhouette Score: {}\".format(\n",
    "        silhouette_score(kmeans_pipe.transform(X), clustered['cluster'])\n",
    "    )\n",
    ")\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider this model our 'baseline' so to speak, it has relatively well distributed clusters, some apparent differences in the average error, bias, and correct call rate (CCR), and has a silhouette score or 0.4115 which is not bad but not good. Before going any further lets try a number of values for $k$ ranging from 2 to 51 solely because there are 51 states plus DC and PR in our data (Note that we did not include state in our variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     k       inertia  silhouette_score\n",
       " 0    2  16081.932580          0.588787\n",
       " 1    3  14067.272930          0.559873\n",
       " 26  28   4722.691140          0.535634\n",
       " 20  22   5383.550621          0.528013\n",
       " 22  24   5114.216432          0.527903,\n",
       "      k       inertia  silhouette_score\n",
       " 0    2  16081.932580          0.588787\n",
       " 3    5  11568.173246          0.411342\n",
       " 48  50   3496.351330          0.427591\n",
       " 49  51   3483.726987          0.388677)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for k in range(2, 52):#\n",
    "    cl  = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('kmeans', KMeans(n_clusters = k, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ")\n",
    "    cl.fit(X)\n",
    "\n",
    "    sil = silhouette_score(cl.transform(X), cl['kmeans'].labels_)\n",
    "\n",
    "    score.append((k, cl['kmeans'].inertia_, sil)) \n",
    "\n",
    "score_df = pd.DataFrame(score, columns = ['k', 'inertia', 'silhouette_score'])\n",
    "\n",
    "score_df.sort_values(\n",
    "    by = ['silhouette_score'], ascending = False\n",
    "    ).head(), score_df.loc[[0, 3, 48, 49], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our best performing values of $k$ are 2 and 3, with a few values in the mid 20s also performing well. We also see that 50 and 51 clusters performed poorly which is to be expected but was worth trying at least. Lets take a look at our 2 and 3 cluster models before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Means Silhouette Score: 0.5887869160751409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5851</td>\n",
       "      <td>-0.141478</td>\n",
       "      <td>5.552343</td>\n",
       "      <td>0.795847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4904</td>\n",
       "      <td>-0.120648</td>\n",
       "      <td>5.457969</td>\n",
       "      <td>0.809543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "0            5851 -0.141478  5.552343  0.795847\n",
       "1            4904 -0.120648  5.457969  0.809543"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 2\n",
    "kmeans_pipe = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('kmeans', KMeans(n_clusters = 2, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "clustered = pd.concat(\n",
    "    [X, pd.Series(kmeans_pipe['kmeans'].labels_, name = 'cluster')]\n",
    "    , axis = 1)\n",
    "\n",
    "print(\n",
    "    \"2-Means Silhouette Score: {}\".format(\n",
    "        silhouette_score(kmeans_pipe.transform(X), clustered['cluster'])\n",
    "    )\n",
    ")\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see these clusters are fairly even in size and also not particularly different in terms of poll accuracy metrics. Let's look at other measurable differences between our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  partisan\n",
       "0        NPL         0.908392\n",
       "         D           0.050761\n",
       "         R           0.040848\n",
       "1        NPL         0.942496\n",
       "         D           0.031403\n",
       "         R           0.026101\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['partisan'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see more Non-Partisan polls in the first cluster but otherwise this isnt' too interesting of an angle so let's try our three most common methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Live Phone</th>\n",
       "      <th>IVR</th>\n",
       "      <th>Online</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>0.014698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00102</td>\n",
       "      <td>0.651101</td>\n",
       "      <td>0.463295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Live Phone       IVR    Online\n",
       "cluster                                \n",
       "0           1.00000  0.027175  0.014698\n",
       "1           0.00102  0.651101  0.463295"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[['Live Phone', 'IVR', 'Online']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our 2-mean model is separating at least partially based on Live Phone methodology, that's interesting and worth keeping in mind for the 3-mean model. Before we move on, let's quickly consider a few more measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  type_simple\n",
       "0        Pres-G         0.249872\n",
       "         Sen-G          0.227482\n",
       "         House-G        0.182704\n",
       "         Pres-P         0.180311\n",
       "         Gov-G          0.159631\n",
       "1        Pres-G         0.299959\n",
       "         Sen-G          0.268352\n",
       "         Gov-G          0.158238\n",
       "         Pres-P         0.155791\n",
       "         House-G        0.117659\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['type_simple'].value_counts(normalize  = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No particular difference here, fewer House races in the second cluster but no clear standouts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_bt_polldate_election</th>\n",
       "      <th>samplesize</th>\n",
       "      <th>margin_poll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.432063</td>\n",
       "      <td>751.575799</td>\n",
       "      <td>2.660118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.163744</td>\n",
       "      <td>1115.345330</td>\n",
       "      <td>2.871540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         days_bt_polldate_election   samplesize  margin_poll\n",
       "cluster                                                     \n",
       "0                        10.432063   751.575799     2.660118\n",
       "1                         9.163744  1115.345330     2.871540"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[\n",
    "    [\n",
    "        'days_bt_polldate_election',\n",
    "        'samplesize',\n",
    "        'margin_poll'\n",
    "    ]\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster one has slightly earlier polls and much smaller sample sizes, likely due to live phone polling having lower response rates, margin is about the same however but let's quickly check the standard deviation for margin and bias because they both can have negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calc_bias</th>\n",
       "      <th>margin_poll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.456059</td>\n",
       "      <td>14.971607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.211605</td>\n",
       "      <td>13.321026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         calc_bias  margin_poll\n",
       "cluster                        \n",
       "0         7.456059    14.971607\n",
       "1         7.211605    13.321026"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[\n",
    "    [\n",
    "        'calc_bias',\n",
    "        'margin_poll'\n",
    "    ]\n",
    "].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly lower bias standard deviation for cluster two, we also see noticeably lower poll margin standard deviation. We have very slight evidence that cluster two is slightly more accurate it seems. Now onto the 3-means model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Means Silhouette Score: 0.5598733195136475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767</td>\n",
       "      <td>-1.335276</td>\n",
       "      <td>5.461211</td>\n",
       "      <td>0.802855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2345</td>\n",
       "      <td>1.454529</td>\n",
       "      <td>5.430520</td>\n",
       "      <td>0.812580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5643</td>\n",
       "      <td>-0.201242</td>\n",
       "      <td>5.565639</td>\n",
       "      <td>0.797360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "0            2767 -1.335276  5.461211  0.802855\n",
       "1            2345  1.454529  5.430520  0.812580\n",
       "2            5643 -0.201242  5.565639  0.797360"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 3\n",
    "kmeans_pipe = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('kmeans', KMeans(n_clusters = 3, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "clustered = pd.concat(\n",
    "    [X, pd.Series(kmeans_pipe['kmeans'].labels_, name = 'cluster')]\n",
    "    , axis = 1)\n",
    "\n",
    "print(\n",
    "    \"3-Means Silhouette Score: {}\".format(\n",
    "        silhouette_score(kmeans_pipe.transform(X), clustered['cluster'])\n",
    "    )\n",
    ")\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  partisan\n",
       "0        NPL         0.926997\n",
       "         D           0.040477\n",
       "         R           0.032526\n",
       "1        NPL         0.955650\n",
       "         D           0.026013\n",
       "         R           0.018337\n",
       "2        NPL         0.909268\n",
       "         D           0.049265\n",
       "         R           0.041467\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['partisan'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there again isn't much difference between error and CCR for this model but we do see a bit of a difference between bias for the three clusters. Its hard to make sense of that just yet but for now we can say that the polls in the first cluster trend towards Republican bias while the polls in the third cluster trend toward Democratic bias. The polls in cluster 2 however seem to trend towards neither. All three clusters are about the same amount of wrong (though cluster two is ~1% more accurate) but the ways in which they are wrong is different. We also see that the cluster sizes have diverged a bit, our third cluster is about half of our observations with the remaining two being about the same size. Let's check methodology, we'd expect to see some trends here that extend what we saw in the 2-means model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Live Phone</th>\n",
       "      <th>IVR</th>\n",
       "      <th>Online</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057102</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.262687</td>\n",
       "      <td>0.993603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998582</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.004962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Live Phone       IVR    Online\n",
       "cluster                                \n",
       "0          0.057102  0.988435  0.000000\n",
       "1          0.026866  0.262687  0.993603\n",
       "2          0.998582  0.000177  0.004962"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[['Live Phone', 'IVR', 'Online']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, our 3-means model managed to separate into the three main methodologies. Remember, these methodologies can be used together so some amount of overlap is expected. Cluster 1 is mainly composed of IVR polls with a handful of live phone polls and no online polls. Cluster 2 has mainly online polls but a quarter of the polls are IVR with a very small number of live phone polls. Lastly, cluster 3 is almost entirely live phone polls with a few IVR and online polls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  type_simple\n",
       "0        Sen-G          0.250813\n",
       "         Pres-G         0.236718\n",
       "         Pres-P         0.192989\n",
       "         Gov-G          0.173473\n",
       "         House-G        0.146007\n",
       "1        Pres-G         0.378678\n",
       "         Sen-G          0.293390\n",
       "         Gov-G          0.139446\n",
       "         Pres-P         0.100213\n",
       "         House-G        0.088273\n",
       "2        Pres-G         0.246323\n",
       "         Sen-G          0.224172\n",
       "         Pres-P         0.186071\n",
       "         House-G        0.183413\n",
       "         Gov-G          0.160021\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['type_simple'].value_counts(normalize  = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some slight differences here, namely cluster 2 has proportionally, more presidential general polls compared to the other groups. Again, we struggle to attribute much meaning here given how even the types are distributed across clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calc_bias</th>\n",
       "      <th>margin_poll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.144516</td>\n",
       "      <td>13.018991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.955245</td>\n",
       "      <td>13.480922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.480267</td>\n",
       "      <td>15.082851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         calc_bias  margin_poll\n",
       "cluster                        \n",
       "0         7.144516    13.018991\n",
       "1         6.955245    13.480922\n",
       "2         7.480267    15.082851"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[\n",
    "    [\n",
    "        'calc_bias',\n",
    "        'margin_poll'\n",
    "    ]\n",
    "].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the standard deviation of bias and poll margin is interesting, our second cluster had the lowest on average bias and has the lowest standard deviation for bias as well. Cluster 3, the biggest one, has the highest standard deviation for both metrics and is much higher for poll margin than the rest. We now may have some slight evidence that cluster 2 captures the 'most accurate' polls in some way. More importantly, we can say that online polls are actually generally well centered around 0 bias in the aggregate which is quite interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler\n",
    "\n",
    "So far we've only worked with a min-max scaler and our original data. Min-max scaler scales values to between 0 and 1 depending on their distance from the minimum and maximum values for that feature which means that all of our categorical variables (coded as 0 and 1) are set as the maximum possible difference from each other. This likely led to our clusters being so well-defined by methodology. With a standard scaler we'd expect slightly different results so let's check and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     k        inertia  silhouette_score\n",
       " 0    2  224418.079078          0.653473\n",
       " 20  22   90639.513827          0.314636\n",
       " 14  16  105750.001434          0.314532\n",
       " 22  24   87424.452103          0.306763\n",
       " 23  25   85964.821563          0.305023,\n",
       "    k        inertia  silhouette_score\n",
       " 0  2  224418.079078          0.653473\n",
       " 1  3  205136.317710          0.258471)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for k in range(2, 31): # Reducing max clusters from 52 to 30 \n",
    "    cl  = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessing_pipe),\n",
    "        ('ss', StandardScaler()), # StandardScaler instead\n",
    "        ('kmeans', KMeans(n_clusters = k, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ")\n",
    "    cl.fit(X)\n",
    "\n",
    "    sil = silhouette_score(cl.transform(X), cl['kmeans'].labels_) \n",
    "\n",
    "    score.append((k, cl['kmeans'].inertia_, sil)) \n",
    "\n",
    "score_df = pd.DataFrame(score, columns = ['k', 'inertia', 'silhouette_score'])\n",
    "\n",
    "score_df.sort_values(\n",
    "    by = ['silhouette_score'], ascending = False\n",
    "    ).head(), score_df.loc[[0, 1], :] # Making sure to check 2 and 3 means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, standard scaler shows very different results from the min-max scaler. Additionally, generally we have worse silhouette scores for standard scaled models. The notable exception is 2-means here which has the highest silhouette score we've seen so far so lets take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Means Silhouette Score: 0.6534730509132135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10107</td>\n",
       "      <td>-0.125055</td>\n",
       "      <td>5.509579</td>\n",
       "      <td>0.808647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>648</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>5.505123</td>\n",
       "      <td>0.699846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "0           10107 -0.125055  5.509579  0.808647\n",
       "1             648 -0.240000  5.505123  0.699846"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 2\n",
    "kmeans_pipe = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('ss', StandardScaler()),\n",
    "        ('kmeans', KMeans(n_clusters = 2, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "clustered = pd.concat(\n",
    "    [X, pd.Series(kmeans_pipe['kmeans'].labels_, name = 'cluster')]\n",
    "    , axis = 1)\n",
    "\n",
    "print(\n",
    "    \"2-Means Silhouette Score: {}\".format(\n",
    "        silhouette_score(kmeans_pipe.transform(X), clustered['cluster'])\n",
    "    )\n",
    ")\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  partisan\n",
       "0        NPL         9937\n",
       "         D            170\n",
       "1        R            367\n",
       "         D            281\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['partisan'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, our model has only separated a small section of the polls but that section has a much lower CCR and twice the bias. We also see the exact same error which is notable but it's hard to discern what that tells us yet. We also see that this model is separating all of the Republican polls and about two-thirds of the of the Democratic polls. They are in the same cluster than has much lower CCR than the main cluster. It seems that second cluster is isolating less accurate polls due to partisan influence but we can't draw any hard conclusions from this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Live Phone</th>\n",
       "      <th>IVR</th>\n",
       "      <th>Online</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.541902</td>\n",
       "      <td>0.305630</td>\n",
       "      <td>0.223805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.584877</td>\n",
       "      <td>0.405864</td>\n",
       "      <td>0.148148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Live Phone       IVR    Online\n",
       "cluster                                \n",
       "0          0.541902  0.305630  0.223805\n",
       "1          0.584877  0.405864  0.148148"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[['Live Phone', 'IVR', 'Online']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have mostly an even distribution of poll methodoology here. There are some differences in IVR and online rates but given the sample size difference this isn't too notable. The standard scaler is very clearly working differently than the min-max scaler as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  type_simple\n",
       "0        Pres-G         0.275749\n",
       "         Sen-G          0.244286\n",
       "         Pres-P         0.175027\n",
       "         Gov-G          0.161472\n",
       "         House-G        0.143465\n",
       "1        House-G        0.302469\n",
       "         Sen-G          0.274691\n",
       "         Pres-G         0.225309\n",
       "         Gov-G          0.120370\n",
       "         Pres-P         0.077160\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['type_simple'].value_counts(normalize  = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some slight differences here, the less accurate cluster twice the proportion of House races and very few Presidential Primary races which makes some sense given the partisan slant that our cluster seems to represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calc_bias</th>\n",
       "      <th>margin_poll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.353117</td>\n",
       "      <td>14.484143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.226516</td>\n",
       "      <td>9.486006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         calc_bias  margin_poll\n",
       "cluster                        \n",
       "0         7.353117    14.484143\n",
       "1         7.226516     9.486006"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[\n",
    "    [\n",
    "        'calc_bias',\n",
    "        'margin_poll'\n",
    "    ]\n",
    "].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking our quick look at standard deviation for margin and bias we see similar spread in bias but much less spread in margins. This again seems to point to systematic issues with the polls in the second cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Principle Component Analysis (PCA) is a method of dimensionality reduction that transforms our data into a set of linear combinations of our features that maximize the variance in our data. In essence, PCA is a tool that can help us separate the valuable information in our data from the noise. This may prove quite valuable because polling has a lot of noise. In the end, the goal of polling is to predict the future and there will always be randomness the poll will not take into account.\n",
    "\n",
    "We will try PCA with both the standard scaler and the min-max scaler because they spread our data out differently so it follows that our PCA will behave differently with the different scalers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     k       inertia  silhouette_score\n",
       " 0    2  13590.609948          0.633850\n",
       " 1    3  11580.460107          0.598354\n",
       " 19  21   3363.467289          0.596041\n",
       " 20  22   3240.350545          0.595020\n",
       " 18  20   3549.065515          0.589247,\n",
       "    k       inertia  silhouette_score\n",
       " 0  2  13590.609948          0.633850\n",
       " 1  3  11580.460107          0.598354)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for k in range(2, 31):\n",
    "    cl  = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        # Choosing the components that give us 85% of the variance in our data\n",
    "        ('pca', PCA(n_components = 0.85)), \n",
    "        ('kmeans', KMeans(n_clusters = k, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ")\n",
    "    cl.fit(X)\n",
    "\n",
    "    sil = silhouette_score(cl.transform(X), cl['kmeans'].labels_)\n",
    "\n",
    "    score.append((k, cl['kmeans'].inertia_, sil))\n",
    "\n",
    "score_df = pd.DataFrame(score, columns = ['k', 'inertia', 'silhouette_score'])\n",
    "\n",
    "score_df.sort_values(\n",
    "    by = ['silhouette_score'], ascending = False\n",
    "    ).head(), score_df.loc[[0, 1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see higher silhouette scores which is interesting, especially for the 2-means model. We also see that 3-means does only slightly better than the 20-22 means models. We'll investigate the 2 and 3 means models to see if they're any different from the clusters from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Means Silhouette Score: 0.6338501807701804\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5849</td>\n",
       "      <td>-0.142424</td>\n",
       "      <td>5.553344</td>\n",
       "      <td>0.795777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4906</td>\n",
       "      <td>-0.119529</td>\n",
       "      <td>5.456814</td>\n",
       "      <td>0.809621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "0            5849 -0.142424  5.553344  0.795777\n",
       "1            4906 -0.119529  5.456814  0.809621"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 2\n",
    "kmeans_pipe = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('pca', PCA(n_components = 0.85)),\n",
    "        ('kmeans', KMeans(n_clusters = 2, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "clustered = pd.concat(\n",
    "    [X, pd.Series(kmeans_pipe['kmeans'].labels_, name = 'cluster')]\n",
    "    , axis = 1)\n",
    "\n",
    "print(\n",
    "    \"2-Means Silhouette Score: {}\".format(\n",
    "        silhouette_score(kmeans_pipe.transform(X), clustered['cluster'])\n",
    "    )\n",
    ")\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  partisan\n",
       "0        NPL         0.908360\n",
       "         D           0.050778\n",
       "         R           0.040862\n",
       "1        NPL         0.942519\n",
       "         D           0.031390\n",
       "         R           0.026091\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['partisan'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These clusters are nearly the same as the ones we had for our 2-mean min-max model without PCA decomposition. For that reason we'll do only a cursory glance at this model. It is interesting that exactly two polls got moved but because this model mainly separated by methodology we can't take too much away here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Live Phone</th>\n",
       "      <th>IVR</th>\n",
       "      <th>Online</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026842</td>\n",
       "      <td>0.014703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.651243</td>\n",
       "      <td>0.463106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Live Phone       IVR    Online\n",
       "cluster                                \n",
       "0          1.000000  0.026842  0.014703\n",
       "1          0.001427  0.651243  0.463106"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[['Live Phone', 'IVR', 'Online']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same as before, we can be satisfied this model is performing very similarly to the one without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Means Silhouette Score: 0.5983536672156453\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5651</td>\n",
       "      <td>-0.197356</td>\n",
       "      <td>5.568252</td>\n",
       "      <td>0.797646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2368</td>\n",
       "      <td>1.389307</td>\n",
       "      <td>5.465532</td>\n",
       "      <td>0.812289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2736</td>\n",
       "      <td>-1.313622</td>\n",
       "      <td>5.425464</td>\n",
       "      <td>0.802449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "0            5651 -0.197356  5.568252  0.797646\n",
       "1            2368  1.389307  5.465532  0.812289\n",
       "2            2736 -1.313622  5.425464  0.802449"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 3\n",
    "kmeans_pipe = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('pca', PCA(n_components = 0.85)),\n",
    "        ('kmeans', KMeans(n_clusters = 3, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "clustered = pd.concat(\n",
    "    [X, pd.Series(kmeans_pipe['kmeans'].labels_, name = 'cluster')]\n",
    "    , axis = 1)\n",
    "\n",
    "print(\n",
    "    \"3-Means Silhouette Score: {}\".format(\n",
    "        silhouette_score(kmeans_pipe.transform(X), clustered['cluster'])\n",
    "    )\n",
    ")\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  partisan\n",
       "0        NPL         0.909397\n",
       "         D           0.049195\n",
       "         R           0.041409\n",
       "1        NPL         0.956503\n",
       "         D           0.025760\n",
       "         R           0.017736\n",
       "2        NPL         0.925804\n",
       "         D           0.040936\n",
       "         R           0.033260\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['partisan'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, these results look quite familiar. We will check methodology again before moving along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Live Phone</th>\n",
       "      <th>IVR</th>\n",
       "      <th>Online</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025760</td>\n",
       "      <td>0.260135</td>\n",
       "      <td>0.983108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Live Phone       IVR    Online\n",
       "cluster                                \n",
       "0          0.997346  0.000000  0.005309\n",
       "1          0.025760  0.260135  0.983108\n",
       "2          0.058114  1.000000  0.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')[['Live Phone', 'IVR', 'Online']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The few polls that moved around due to PCA seem to have made the clusters a bit purer with regards to methodology. So far it seems that PCA has improved our clustering but not changed them by a large margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     k        inertia  silhouette_score\n",
       " 0    2  192654.792815          0.675127\n",
       " 19  21   69983.212980          0.300875\n",
       " 10  12   98391.385355          0.298260\n",
       " 12  14   85879.860042          0.295490\n",
       " 18  20   71749.739544          0.295341,\n",
       " k                        2.000000\n",
       " inertia             192654.792815\n",
       " silhouette_score         0.675127\n",
       " Name: 0, dtype: float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for k in range(2, 31): # Reducing max clusters from 52 to 30 \n",
    "    cl  = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', preprocessing_pipe),\n",
    "        ('ss', StandardScaler()), # StandardScaler instead\n",
    "        ('pca', PCA(n_components = 0.85)),\n",
    "        ('kmeans', KMeans(n_clusters = k, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ")\n",
    "    cl.fit(X)\n",
    "\n",
    "    sil = silhouette_score(cl.transform(X), cl['kmeans'].labels_) \n",
    "\n",
    "    score.append((k, cl['kmeans'].inertia_, sil)) \n",
    "\n",
    "score_df = pd.DataFrame(score, columns = ['k', 'inertia', 'silhouette_score'])\n",
    "\n",
    "score_df.sort_values(\n",
    "    by = ['silhouette_score'], ascending = False\n",
    "    ).head(), score_df.loc[0, :] # Making sure to check 2 means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see similar results as what we saw before applying PCA but let's take a look at our 2-means model again before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Means Silhouette Score: 0.6751270446822838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10107</td>\n",
       "      <td>-0.125055</td>\n",
       "      <td>5.509579</td>\n",
       "      <td>0.808647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>648</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>5.505123</td>\n",
       "      <td>0.699846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "0           10107 -0.125055  5.509579  0.808647\n",
       "1             648 -0.240000  5.505123  0.699846"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k = 2\n",
    "kmeans_pipe = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('ss', StandardScaler()),\n",
    "        ('pca', PCA(n_components = 0.85)),\n",
    "        ('kmeans', KMeans(n_clusters = 2, n_init = 30, random_state = 42))\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "clustered = pd.concat(\n",
    "    [X, pd.Series(kmeans_pipe['kmeans'].labels_, name = 'cluster')]\n",
    "    , axis = 1)\n",
    "\n",
    "print(\n",
    "    \"2-Means Silhouette Score: {}\".format(\n",
    "        silhouette_score(kmeans_pipe.transform(X), clustered['cluster'])\n",
    "    )\n",
    ")\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the exact same values as we saw before along with the exact same cluster size so we can surmise that PCA did nothing except inflate our silhouette score due to maximizing the variance in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that PCA is valuable and does improve the performance of our clustering but does not actually change our clusters by much. Moving forward we will be applying PCA from the start to ensure our models are as effective as possible though it will likely make no major difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "DBSCAN is a density based clustering algorithm that separates the data into clusters as appropriate and designates outliers of data points that don't fit into any possible cluster. It should perform differently from K-Means and we suspect that there will be a number of outliers identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN doesn't have a transform method so we need to process our data separately\n",
    "dbscan_prep = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('pca', PCA(n_components = 0.85))\n",
    "    ]\n",
    ").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding good values of epsilon and min_samples is crucial so we set a wide range\n",
    "# \n",
    "score = []\n",
    "\n",
    "for min_sample in range(5, 100, 5):\n",
    "    for eps in range(2, 20): # The max value here came from trial and error (eps >= 1 throws an error)\n",
    "        db = DBSCAN(eps = eps/20, min_samples = min_sample, n_jobs = 4)\n",
    "        db.fit(dbscan_prep.transform(X))\n",
    "\n",
    "        sil = silhouette_score(dbscan_prep.transform(X), db.labels_)\n",
    "\n",
    "        score.append((eps/10, min_sample, sil))\n",
    "\n",
    "score_db = pd.DataFrame(score, columns = ['eps', 'min_samples', 'silhouette_score'])\n",
    "score_db.sort_values(by = ['silhouette_score'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.422936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.421476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.9</td>\n",
       "      <td>15</td>\n",
       "      <td>0.416802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.9</td>\n",
       "      <td>25</td>\n",
       "      <td>0.414523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.413423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eps  min_samples  silhouette_score\n",
       "61  0.9           20          0.422936\n",
       "25  0.9           10          0.421476\n",
       "43  0.9           15          0.416802\n",
       "79  0.9           25          0.414523\n",
       "7   0.9            5          0.413423"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eps = 0.9, min_samples = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have quite low silhouette scores here which is unfortunate but we can take a look at our best performing hyper-parameters and see if we get anything particularly useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>28</td>\n",
       "      <td>-1.751071</td>\n",
       "      <td>6.143929</td>\n",
       "      <td>0.267857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10727</td>\n",
       "      <td>-0.127754</td>\n",
       "      <td>5.507655</td>\n",
       "      <td>0.803487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias               error rightcall\n",
       "            count      mean      mean      mean\n",
       "cluster                                        \n",
       "-1             28 -1.751071  6.143929  0.267857\n",
       " 0          10727 -0.127754  5.507655  0.803487"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps = 0.9, min_samples = 20, n_jobs = 4).fit(\n",
    "    dbscan_prep.transform(X)\n",
    "    )\n",
    "\n",
    "clustered = pd.concat([X, pd.Series(dbscan.labels_, name = 'cluster')], axis = 1)\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model was only able to find 28 outliers and no clusters, but those outliers were much less accurate than the rest of the polls. Let's investigate the 28 before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">year</th>\n",
       "      <th colspan=\"4\" halign=\"left\">anon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>2012</td>\n",
       "      <td>2018.250000</td>\n",
       "      <td>2019.5</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>2010.229235</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year                            anon                     \n",
       "          min         mean  median   max  min      mean median max\n",
       "cluster                                                           \n",
       "-1       2012  2018.250000  2019.5  2020    0  0.964286    1.0   1\n",
       " 0       1998  2010.229235  2010.0  2020    0  0.043069    0.0   1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These two features and metrics were isolated by using .describe() \n",
    "# For the sake of brevity only the relevant features and metric are kept\n",
    "clustered.groupby('cluster')[['year', 'anon']].agg(['min', 'mean', 'median', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our model has managed to isolate a strand of modern polls that were mostly sponsered by anonymous partisan operatives that were *much* less accurate than typical polls are. Let's check our partisan variable to see if we have any interesting result there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster  partisan\n",
       "-1       D             15\n",
       "         R             13\n",
       " 0       NPL         9937\n",
       "         D            436\n",
       "         R            354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered.groupby('cluster')['partisan'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even amount of each which is less scandalous than it could have been but still a notable result. All in all, DBSCAN managed to identify 28 polls that performed quite poorly which is an accomplishment in itself with how poorly or models have done at identifying differences in CCR so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_prep = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('ss', StandardScaler()),\n",
    "        ('pca', PCA(n_components = 0.85))\n",
    "    ]\n",
    ").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.095208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.088517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.078591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2.9</td>\n",
       "      <td>25</td>\n",
       "      <td>0.077756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.075080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eps  min_samples  silhouette_score\n",
       "24   2.9            5          0.095208\n",
       "23   2.8            5          0.088517\n",
       "49   2.9           10          0.078591\n",
       "124  2.9           25          0.077756\n",
       "99   2.9           20          0.075080"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for min_sample in range(5, 100, 5):\n",
    "        for eps in range(5, 30):\n",
    "            # Avoiding a value error that comes up with some ratios of eps : min_samples\n",
    "            # If the algorithm assigns everything to 1 group then the exception is triggered.\n",
    "            # You can only calculate a silhouette score if there are 2 or more groups.\n",
    "            try: \n",
    "                db = DBSCAN(eps = eps/20, min_samples = min_sample, n_jobs = 4)\n",
    "                db.fit(dbscan_prep.transform(X))\n",
    "                \n",
    "                sil = silhouette_score(dbscan_prep.transform(X), db.labels_)\n",
    "            except ValueError:\n",
    "                sil = np.nan\n",
    "            score.append((eps/10, min_sample, sil))\n",
    "\n",
    "score_db = pd.DataFrame(score, columns = ['eps', 'min_samples', 'silhouette_score'])\n",
    "score_db.sort_values(by = ['silhouette_score'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is shockingly poor performance. We can check if the issue is with standard scaling or with applying PCA to standard scaled data but before that let's take a look at one of these models just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>147</td>\n",
       "      <td>-1.672517</td>\n",
       "      <td>11.900748</td>\n",
       "      <td>0.636054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9268</td>\n",
       "      <td>-0.276293</td>\n",
       "      <td>5.495708</td>\n",
       "      <td>0.810747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>0.645802</td>\n",
       "      <td>4.969771</td>\n",
       "      <td>0.774809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>413</td>\n",
       "      <td>0.111961</td>\n",
       "      <td>5.045182</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>402</td>\n",
       "      <td>1.426070</td>\n",
       "      <td>4.126368</td>\n",
       "      <td>0.670398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>5.511111</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>1.776000</td>\n",
       "      <td>3.176000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.023333</td>\n",
       "      <td>7.081111</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>-0.823333</td>\n",
       "      <td>4.688182</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>9.614286</td>\n",
       "      <td>10.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>4.183333</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3.756000</td>\n",
       "      <td>4.488000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66</td>\n",
       "      <td>-1.017121</td>\n",
       "      <td>5.551667</td>\n",
       "      <td>0.780303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>190</td>\n",
       "      <td>2.832263</td>\n",
       "      <td>5.930474</td>\n",
       "      <td>0.768421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34</td>\n",
       "      <td>-2.118824</td>\n",
       "      <td>2.795882</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>6.545556</td>\n",
       "      <td>6.545556</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>8.755000</td>\n",
       "      <td>8.755000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>6.954000</td>\n",
       "      <td>6.954000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias                error rightcall\n",
       "            count      mean       mean      mean\n",
       "cluster                                         \n",
       "-1            147 -1.672517  11.900748  0.636054\n",
       " 0           9268 -0.276293   5.495708  0.810747\n",
       " 1            131  0.645802   4.969771  0.774809\n",
       " 2            413  0.111961   5.045182  0.857143\n",
       " 3            402  1.426070   4.126368  0.670398\n",
       " 4              9  3.040000   5.511111  0.388889\n",
       " 5             15  1.776000   3.176000  0.900000\n",
       " 6              9 -0.023333   7.081111  0.888889\n",
       " 7             33 -0.823333   4.688182  0.787879\n",
       " 8              7  9.614286  10.160000  1.000000\n",
       " 9              6  4.183333   5.300000  0.333333\n",
       " 10             5  3.756000   4.488000  1.000000\n",
       " 11            66 -1.017121   5.551667  0.780303\n",
       " 12           190  2.832263   5.930474  0.768421\n",
       " 13            34 -2.118824   2.795882  0.529412\n",
       " 14             9  6.545556   6.545556  0.777778\n",
       " 15             6  8.755000   8.755000  0.583333\n",
       " 16             5  6.954000   6.954000  0.600000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps = 2.9, min_samples = 5, n_jobs = 4).fit(\n",
    "    dbscan_prep.transform(X)\n",
    "    )\n",
    "\n",
    "clustered = pd.concat([X, pd.Series(dbscan.labels_, name = 'cluster')], axis = 1)\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's simple too many clusters to make much sense of but it does seem capable of separating some of the low CCR polls. It is very likely that the result is simply due to very small clusters for the most part so we're going to move on to checking if PCA is the issue here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.065546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.047925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.036884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.031960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eps  min_samples  silhouette_score\n",
       "24  2.9            5          0.065546\n",
       "23  2.8            5          0.047925\n",
       "22  2.7            5          0.038718\n",
       "49  2.9           10          0.036884\n",
       "48  2.8           10          0.031960"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan_prep = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('ss', StandardScaler()),\n",
    "        # ('pca', PCA(n_components = 0.85)) No PCA this time\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "\n",
    "score = []\n",
    "# Same hyper-paramters as before\n",
    "for min_sample in range(5, 100, 5):\n",
    "        for eps in range(5, 30):\n",
    "            try: \n",
    "                db = DBSCAN(eps = eps/20, min_samples = min_sample, n_jobs = 4)\n",
    "                db.fit(dbscan_prep.transform(X))\n",
    "                \n",
    "                sil = silhouette_score(dbscan_prep.transform(X), db.labels_)\n",
    "            except ValueError:\n",
    "                sil = np.nan\n",
    "            score.append((eps/10, min_sample, sil))\n",
    "\n",
    "score_db = pd.DataFrame(score, columns = ['eps', 'min_samples', 'silhouette_score'])\n",
    "score_db.sort_values(by = ['silhouette_score'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, it seems like standard scaler just doesn't work well with DBSCAN in this case. We will move on and set DBSCAN aside in favor of a different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heriarchical DBSCAN (HDBSCAN)\n",
    "\n",
    "The main flaw of DBSCAN is that it performs poorly on data with varying densities. That is, when some of the data is clustered tight and some of the data is clustered over a large area, DBSCAN has a hard time properly assigning clusters. HDBSCAN aims to solve this issue by automatically varying the density checked for clusters. In short, HDBSCAN can detect clusters with varying densities while DBSCAN cannot. A helpful reference can be found [here](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaler\n",
    "\n",
    "We will start with min-max scaling because standard scaling performed quite poorly with DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_prep = Pipeline(\n",
    "    [\n",
    "        ('pre', preprocessing_pipe),\n",
    "        ('min_max', MinMaxScaler()),\n",
    "        ('pca', PCA(n_components = 0.85))\n",
    "    ]\n",
    ").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for min_sample in range(15, 100, 5):\n",
    "        for min_cluster_size in range(5, 100, 5):\n",
    "            hdb = HDBSCAN(\n",
    "                  min_cluster_size = min_cluster_size, \n",
    "                  min_samples = min_sample, \n",
    "                  n_jobs = 4\n",
    "            )\n",
    "            hdb.fit(hdbscan_prep.transform(X))\n",
    "\n",
    "            sil = silhouette_score(hdbscan_prep.transform(X), hdb.labels_)\n",
    "\n",
    "            score.append((min_cluster_size, min_sample, sil))\n",
    "\n",
    "score_db = pd.DataFrame(score, columns = ['min_cluster', 'min_samples', 'silhouette_score'])\n",
    "score_db.sort_values(by = ['silhouette_score'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_cluster</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>75.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.382961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>70.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.382961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>85.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.379923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>80.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.379923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>95.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.376771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     min_cluster  min_samples  silhouette_score\n",
       "603         75.0           45          0.382961\n",
       "602         70.0           45          0.382961\n",
       "605         85.0           45          0.379923\n",
       "604         80.0           45          0.379923\n",
       "607         95.0           45          0.376771"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_db.sort_values(by = ['silhouette_score'], ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like HDBSCAN is doing a worse job than DBSCAN but we should look at our best models before making any decisions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">calc_bias</th>\n",
       "      <th>error</th>\n",
       "      <th>rightcall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1414</td>\n",
       "      <td>-0.310035</td>\n",
       "      <td>6.184717</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>474</td>\n",
       "      <td>1.520127</td>\n",
       "      <td>5.634768</td>\n",
       "      <td>0.862869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>2.102214</td>\n",
       "      <td>4.472443</td>\n",
       "      <td>0.923664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481</td>\n",
       "      <td>-1.314699</td>\n",
       "      <td>4.578274</td>\n",
       "      <td>0.995842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85</td>\n",
       "      <td>-5.456471</td>\n",
       "      <td>7.740471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123</td>\n",
       "      <td>-3.306911</td>\n",
       "      <td>8.724634</td>\n",
       "      <td>0.979675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121</td>\n",
       "      <td>1.806777</td>\n",
       "      <td>4.159835</td>\n",
       "      <td>0.979339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>372</td>\n",
       "      <td>-0.760000</td>\n",
       "      <td>5.614516</td>\n",
       "      <td>0.865591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>940</td>\n",
       "      <td>-0.304521</td>\n",
       "      <td>4.906777</td>\n",
       "      <td>0.994681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>124</td>\n",
       "      <td>0.813145</td>\n",
       "      <td>6.568629</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>485</td>\n",
       "      <td>-0.089588</td>\n",
       "      <td>4.468309</td>\n",
       "      <td>0.883505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>223</td>\n",
       "      <td>1.685605</td>\n",
       "      <td>5.959955</td>\n",
       "      <td>0.780269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>194</td>\n",
       "      <td>1.504021</td>\n",
       "      <td>7.083402</td>\n",
       "      <td>0.726804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>659</td>\n",
       "      <td>2.845630</td>\n",
       "      <td>4.634825</td>\n",
       "      <td>0.854325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>160</td>\n",
       "      <td>2.388438</td>\n",
       "      <td>4.180313</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>375</td>\n",
       "      <td>-0.843413</td>\n",
       "      <td>6.835627</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79</td>\n",
       "      <td>-11.808481</td>\n",
       "      <td>11.808481</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>819</td>\n",
       "      <td>-1.342527</td>\n",
       "      <td>7.275214</td>\n",
       "      <td>0.998779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>189</td>\n",
       "      <td>-11.472011</td>\n",
       "      <td>11.758148</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>582</td>\n",
       "      <td>1.176237</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>175</td>\n",
       "      <td>2.919029</td>\n",
       "      <td>7.324400</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>694</td>\n",
       "      <td>0.055086</td>\n",
       "      <td>4.794092</td>\n",
       "      <td>0.997839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>7.845385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>408</td>\n",
       "      <td>-0.771397</td>\n",
       "      <td>3.716054</td>\n",
       "      <td>0.996324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>85</td>\n",
       "      <td>-2.343176</td>\n",
       "      <td>5.676118</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1026</td>\n",
       "      <td>0.716647</td>\n",
       "      <td>3.446082</td>\n",
       "      <td>0.994152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>233</td>\n",
       "      <td>-0.461416</td>\n",
       "      <td>5.224249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        calc_bias                 error rightcall\n",
       "            count       mean       mean      mean\n",
       "cluster                                          \n",
       "-1           1414  -0.310035   6.184717  0.568600\n",
       " 0            474   1.520127   5.634768  0.862869\n",
       " 1            131   2.102214   4.472443  0.923664\n",
       " 2            481  -1.314699   4.578274  0.995842\n",
       " 3             85  -5.456471   7.740471  0.000000\n",
       " 4            123  -3.306911   8.724634  0.979675\n",
       " 5            121   1.806777   4.159835  0.979339\n",
       " 6            372  -0.760000   5.614516  0.865591\n",
       " 7            940  -0.304521   4.906777  0.994681\n",
       " 8            124   0.813145   6.568629  0.004032\n",
       " 9            485  -0.089588   4.468309  0.883505\n",
       " 10           223   1.685605   5.959955  0.780269\n",
       " 11           194   1.504021   7.083402  0.726804\n",
       " 12           659   2.845630   4.634825  0.854325\n",
       " 13           160   2.388438   4.180313  0.718750\n",
       " 14           375  -0.843413   6.835627  1.000000\n",
       " 15            79 -11.808481  11.808481  0.006329\n",
       " 16           819  -1.342527   7.275214  0.998779\n",
       " 17           189 -11.472011  11.758148  0.002646\n",
       " 18           582   1.176237   4.900000  1.000000\n",
       " 19           175   2.919029   7.324400  0.002857\n",
       " 20           694   0.055086   4.794092  0.997839\n",
       " 21           104   0.607692   7.845385  0.000000\n",
       " 22           408  -0.771397   3.716054  0.996324\n",
       " 23            85  -2.343176   5.676118  0.000000\n",
       " 24          1026   0.716647   3.446082  0.994152\n",
       " 25           233  -0.461416   5.224249  0.000000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdbscan = HDBSCAN(min_cluster_size = 75, min_samples = 45, n_jobs = 4).fit(\n",
    "    hdbscan_prep.transform(X)\n",
    "    )\n",
    "\n",
    "clustered = pd.concat([X, pd.Series(hdbscan.labels_, name = 'cluster')], axis = 1)\n",
    "\n",
    "clustered.groupby('cluster')[['calc_bias', 'error', 'rightcall']].agg(\n",
    "    {\n",
    "    'calc_bias' : ['count', 'mean'],\n",
    "    'error' : ['mean'],\n",
    "    'rightcall' : ['mean']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
